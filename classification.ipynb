{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mamadoz79/NLP-CA/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout, Bidirectional, LSTM\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "j8Ekh_8vqWCw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hazm\n",
        "from hazm import word_tokenize"
      ],
      "metadata": {
        "id": "kZalULRiqapS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f418d908-9eff-493d-e40c-bf88ac154380"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hazm\n",
            "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 14.1 MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1\n",
            "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 50.9 MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 32.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394487 sha256=96da5ce36b1c5e16d2a9ae5967bc6a96dfd2a31f95de68741fc1b0c122e1a3ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=153948 sha256=4c908631b515bb1736ab7d0969e755c5bc21cfddf0919399af1b64848def459b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mix5-tAgqbbq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e64e5a42-ba04-46b0-92db-6dcb4e7820eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"drive/MyDrive/NLP/PersianStopWords.txt\", encoding = 'utf-8')\n",
        "stopwords = set(i.strip() for i in file.readlines())"
      ],
      "metadata": {
        "id": "qytSdHdiqcmS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/NLP/tokenizer.h5', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)"
      ],
      "metadata": {
        "id": "hCEeI7_drsic"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/NLP/hamshahri.csv\")\n",
        "data = data[data.groupby('cat')['cat'].transform('count') > 1000]\n",
        "data = data[data['corpus'].str.len() <= 10_000]\n",
        "num_unique_categories = data['cat'].nunique()"
      ],
      "metadata": {
        "id": "1QMltnL_sRhq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index)+1\n",
        "data_to_sequences = tokenizer.texts_to_sequences(list(data['corpus']))\n",
        "maxlen = max(len(i) for i in data_to_sequences)"
      ],
      "metadata": {
        "id": "U1lhZKX2r7wk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_data_to_sequences = pad_sequences(data_to_sequences, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "F_oEGTk4scC5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = pd.get_dummies(data['cat']).values"
      ],
      "metadata": {
        "id": "LWnZqtVIs15w"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_one_hot = pd.get_dummies(data['cat'])\n",
        "category_types = Y_one_hot.columns.values"
      ],
      "metadata": {
        "id": "2jRLoS7N3jmm"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(pad_data_to_sequences, Y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "20NhwJ-0sfl8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=maxlen))\n",
        "model.add(Bidirectional(LSTM(200, return_sequences=True)))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_unique_categories, activation='softmax'))"
      ],
      "metadata": {
        "id": "iG-F9P4zsgmG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OgfCH1fesiB5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wbvb9N5sjI6",
        "outputId": "30483c6f-21b1-4dab-a0dc-5ae55cb441eb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 2234, 50)          22836750  \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 2234, 400)        401600    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 400)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 400)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 200)               80200     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 22)                4422      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,322,972\n",
            "Trainable params: 23,322,972\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=7, batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3IzDXBZslF8",
        "outputId": "e13da226-eba6-46c5-dee1-a299030836e2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "400/400 [==============================] - 390s 950ms/step - loss: 2.6668 - accuracy: 0.1583 - val_loss: 2.4808 - val_accuracy: 0.2205\n",
            "Epoch 2/7\n",
            "400/400 [==============================] - 384s 960ms/step - loss: 2.4403 - accuracy: 0.2323 - val_loss: 2.4152 - val_accuracy: 0.2336\n",
            "Epoch 3/7\n",
            "400/400 [==============================] - 383s 957ms/step - loss: 2.2895 - accuracy: 0.2731 - val_loss: 2.4293 - val_accuracy: 0.2271\n",
            "Epoch 4/7\n",
            "400/400 [==============================] - 380s 951ms/step - loss: 2.0912 - accuracy: 0.3297 - val_loss: 2.5338 - val_accuracy: 0.2195\n",
            "Epoch 5/7\n",
            "400/400 [==============================] - 378s 946ms/step - loss: 1.8573 - accuracy: 0.3944 - val_loss: 2.7281 - val_accuracy: 0.2076\n",
            "Epoch 6/7\n",
            "400/400 [==============================] - 380s 950ms/step - loss: 1.6102 - accuracy: 0.4665 - val_loss: 3.1293 - val_accuracy: 0.1951\n",
            "Epoch 7/7\n",
            "400/400 [==============================] - 376s 939ms/step - loss: 1.3833 - accuracy: 0.5381 - val_loss: 3.6008 - val_accuracy: 0.1915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')\n",
        "!cp -r \"/content/model.h5\" \"/content/drive/MyDrive/NLP/model.h5\""
      ],
      "metadata": {
        "id": "KEehrbe-s5zP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = lambda text, stopwords : ' '.join([w for w in word_tokenize(text) if w not in stopwords])"
      ],
      "metadata": {
        "id": "9gDImqhS1cxF"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(texts, stopwords):\n",
        "  cleaned_text = preprocess(texts, stopwords)\n",
        "  text_to_sequences = tokenizer.texts_to_sequences([cleaned_text])\n",
        "  pad_text_to_sequences = pad_sequences(text_to_sequences, maxlen=2234)\n",
        "  category = model.predict([pad_text_to_sequences])[0]\n",
        "  return category_types[np.where(category == max(category))]"
      ],
      "metadata": {
        "id": "rnOjfF2E1eS_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = data['corpus'][2]"
      ],
      "metadata": {
        "id": "Tfb-JtpA3Thp"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(example_text, stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXfnmJur3VN3",
        "outputId": "80d7fc27-0d4b-4cae-9680-1dbbfc2a6251"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['adabh'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['cat'][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_A-aGY5o3r8i",
        "outputId": "51bd2f01-5c32-4552-b664-7a7c879e3941"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'adabh'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NLP",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
